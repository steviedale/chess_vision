{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imutils\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'train': pd.read_csv('/home/stevie/datasets/chess_vision/256x256/dataframes/train.csv'),\n",
    "    'test': pd.read_csv('/home/stevie/datasets/chess_vision/256x256/dataframes/test.csv'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] describing images...\")\n",
    "# initialize the raw pixel intensities matrix, the features matrix,\n",
    "# and labels list\n",
    "images = {}\n",
    "features = {}\n",
    "labels = {}\n",
    "for set_str in 'train', 'test':\n",
    "    images[set_str] = []\n",
    "    features[set_str] = []\n",
    "    labels[set_str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "\t# personally hate the way this is done\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42573it [00:51, 830.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12027it [00:15, 773.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for set_str, df in df_dict.items():\n",
    "\tprint(len(df))\n",
    "\tfor i, row in tqdm(df.iterrows()):\n",
    "\t\t# load the image and extract the class label (assuming that our\n",
    "\t\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "\t\timage = cv2.imread(row['path'])\n",
    "\t\tlabel = row['label']\n",
    "\t\t# extract raw pixel intensity \"features\", followed by a color\n",
    "\t\t# histogram to characterize the color distribution of the pixels\n",
    "\t\t# in the image\n",
    "\t\tpixels = image_to_feature_vector(image)\n",
    "\t\thist = extract_color_histogram(image)\n",
    "\t\t# update the raw images, features, and labels matricies,\n",
    "\t\t# respectively\n",
    "\t\timages[set_str].append(pixels)\n",
    "\t\tfeatures[set_str].append(hist)\n",
    "\t\tlabels[set_str].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[INFO] pixels matrix: 127.72MB\n",
      "[INFO] features matrix: 85.15MB\n",
      "test\n",
      "[INFO] pixels matrix: 36.08MB\n",
      "[INFO] features matrix: 24.05MB\n"
     ]
    }
   ],
   "source": [
    "for set_str in 'train', 'test':\n",
    "    images[set_str] = np.array(images[set_str])\n",
    "    features[set_str] = np.array(features[set_str])\n",
    "    labels[set_str] = np.array(labels[set_str])\n",
    "\n",
    "    print(set_str)\n",
    "    print(\"[INFO] pixels matrix: {:.2f}MB\".format(images[set_str].nbytes / (1024 * 1000.0)))\n",
    "    print(\"[INFO] features matrix: {:.2f}MB\".format(features[set_str].nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion: entropy\n",
      "\tAccuracy: 0.04099110335079405\n",
      "\tFit Time: 0.004668886626304096\n",
      "\tEval Time: 5.507574242388626e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:44<07:28, 224.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy: 0.051134946370666\n",
      "\tFit Time: 0.0006003168581112985\n",
      "\tEval Time: 4.913282184278894e-07\n",
      "criterion: gini\n",
      "\tAccuracy: 0.046229317369252516\n",
      "\tFit Time: 0.0040142859632597665\n",
      "\tEval Time: 4.381117325545923e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [06:46<03:19, 199.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy: 0.02619107009229234\n",
      "\tFit Time: 0.0002696654919413379\n",
      "\tEval Time: 4.993171339827185e-07\n",
      "criterion: log_loss\n",
      "\tAccuracy: 0.036002328095119315\n",
      "\tFit Time: 0.004674521482226304\n",
      "\tEval Time: 4.225700209045029e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [10:31<00:00, 210.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy: 0.03924503201130789\n",
      "\tFit Time: 0.0005978720274328404\n",
      "\tEval Time: 4.6268309937893647e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = {'input_type': [], 'criterion': [], 'fit_time': [], 'eval_time': [], 'accuracy': []}\n",
    "for criterion in tqdm(('entropy', 'gini', 'log_loss')):\n",
    "    print(f\"criterion: {criterion}\")\n",
    "    for input_label, input_data in ('images', images), ('features', features):\n",
    "        # Create Decision Tree classifer object\n",
    "        clf = DecisionTreeClassifier(criterion=criterion)\n",
    "\n",
    "        # Train Decision Tree Classifer\n",
    "        t0 = time.time()\n",
    "        clf = clf.fit(input_data['train'], labels['train'])\n",
    "        t1 = time.time()\n",
    "        fit_time = (t1 - t0) / len(input_data['train'])\n",
    "\n",
    "        #Predict the response for test dataset\n",
    "        t0 = time.time()\n",
    "        y_pred = clf.predict(input_data['test'])\n",
    "        t1 = time.time()\n",
    "        eval_time = (t1 - t0) / len(input_data['test'])\n",
    "\n",
    "        # Model Accuracy, how often is the classifier correct?\n",
    "        acc = metrics.accuracy_score(labels['test'], y_pred)\n",
    "\n",
    "        print(f\"\\tAccuracy: {acc}\")\n",
    "        print(f\"\\tFit Time: {fit_time}\")\n",
    "        print(f\"\\tEval Time: {eval_time}\")\n",
    "\n",
    "        data['input_type'].append(input_label)\n",
    "        data['criterion'].append(criterion)\n",
    "        data['fit_time'].append(fit_time)\n",
    "        data['eval_time'].append(eval_time)\n",
    "        data['accuracy'].append(acc)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df.to_csv('results/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13639fb57c0d6e77b6df30eaff549af56586b1fadc762c3f5b241243bf02e0d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
